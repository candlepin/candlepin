# file based inputs for candlepin related logs.
# An alternative would be logback config to use
# a logstash or syslog target.

input {
  file {
    path => "/var/log/candlepin/candlepin.log"
    start_position => beginning
    type => "candlepin"
  }
  file {
    path => "/var/log/candlepin/access.log"
    start_position => beginning
    type => "candlepin_access"
    }

  file {
    path => "/var/log/candlepin/audit.log"
    start_position => beginning
    type => "candlepin_audit"
    }

  file {
    path => "/var/log/candlepin/error.log"
    start_position => beginning
    type => "candlepin_error"
    }

  file {
    path => "/var/log/rhsm/rhsm.log"
    type => "rhsm"
    start_position => beginning
  }

#  file {
#    path => "/var/log/tomcat/catalina.*.log"
#    type => "tomcat_catalina"
#    start_position => beginning
#    sincedb_path => "/tmp/tomcata_catalina.sincedb"
#    }
}

filter {
  # Candlepin's accesslog (/var/log/candlepin/access.log). Setup with
  # tomcats AccessValve in candlepin tomcats config.
  # Mostly apache combined log format, but also including the request uuid.
  if [type] == "candlepin_access" {
    multiline {
       # Grok pattern names are valid! :)
       pattern => "^%{IPORHOST:clientip} "
       negate => true
       what => previous
    }
    grok {
        match => { "message" => "%{COMBINEDAPACHELOG} %{QUOTEDSTRING:candlepin_access_req_info}" }
        }

    kv { prefix => "candlepin_access_req_info_"
         field_split => ","
         trimkey => "<>\[\]\","
         trim => "<>\[\]\""
         field_split => ","
         source => candlepin_access_req_info }

    mutate {
        rename => [ "candlepin_access_req_info_req", "request_uuid" ]
        rename => [ "candlepin_access_req_info_req_time", "request_time_spent"]
        }

    date {
        match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
  }

  # Primary candlepin log (/var/log/candlepin/candlepin.log).
  # Based on log4j java style logging, but with app specific messages.
  if [type] == "candlepin" {
    # We use multiline logging with no remorse, no regrets. This gets logstash
    # to compress them into one entry (basically, everything between timestamps).
    multiline {
       # Grok pattern names are valid! :)
       pattern => "^%{TIMESTAMP_ISO8601} "
       negate => true
       what => previous
    }

    grok {
        match => { 
            "message" => "%{TIMESTAMP_ISO8601:candlepin_timestamp} \[%{DATA:candlepin_req_info}\]\s+%{LOGLEVEL:candlepin_loglevel}\s+%{JAVACLASS:candlepin_java_class} - \s?%{GREEDYDATA:candlepin_message}"
        }
    }

    # look for debug url headers

    kv { prefix => "candlepin_"
         field_split => ","
         source => candlepin_req_info }

# turn off till we get logstash sorted
#    kv { prefix => "candlepin_msg_"
#         trimkey => "<>\[\],"
#         trim => "<>\[\],"
#         source => candlepin_message
#         }

    mutate {
        # It's useful to have candlepin logs and rhsm/subscription-manager logs both
        # create a "request_uuid" so we can follow a request across client and server logs.
        rename => [ "candlepin_req", "request_uuid" ]
        replace =>  [ "@message", "%{candlepin_message}"]
        replace => [ "loglevel", "%{candlepin_loglevel}" ]
        add_field => { "program_name" => "candlepin" }
        }


    date {
        match => ["candlepin_timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss,SSS" ]
        }
    # could extract the debug headers and kv with ':' as split
    }

  # /var/log/candlepin/error.log
  if [type] == "candlepin_error" {
    multiline {
       # Grok pattern names are valid! :)
       pattern => "^%{TIMESTAMP_ISO8601} "
       negate => true
       what => previous
    }


    # make a pattern
    grok {
        match => { 
            "message" => "%{TIMESTAMP_ISO8601:candlepin_timestamp} \[%{DATA:candlepin_req_info}\]\s+%{LOGLEVEL:candlepin_loglevel}\s+%{JAVACLASS:candlepin_java_class} -\s?%{GREEDYDATA:candlepin_message}"
        }
    }

    kv { prefix => "candlepin_"
         source => candlepin_req_info }

    date {
        match => ["candlepin_timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss,SSS" ]
        }
    }


  # /var/log/candlepin/audit.log
  # Basically a log of all the entitlement events we send out on the message bus.
  if [type] == "candlepin_audit" {
    multiline {
       # Grok pattern names are valid! :)
       pattern => "^%{TIMESTAMP_ISO8601} "
       negate => true
       what => previous
    }

    grok {
        match => {
            "message" => "%{TIMESTAMP_ISO8601:candlepin_timestamp} %{GREEDYDATA:candlepin_audit_message}"
            }
    }

    kv { prefix => "candlepin_audit_"
         trimkey => "<>\[\],"
         trim => "<>\[\],"
         source => candlepin_audit_message}

    date {
        match => ["candlepin_timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss,SSS",
                  "YYYY-MM-dd HH:mm:ssZ"]
        }
    }


  # /var/log/rhsm/rhsm.log
  # The log file used for a consumer clients subscription-manager, python-rhsm, and virt-who.
  if [type] == "rhsm" {

    multiline {
       # Grok pattern names are valid! :)
       pattern => "^%{TIMESTAMP_ISO8601} "
       negate => true
       what => previous
    }

    grok {
        match => { "message" => [
            "%{TIMESTAMP_ISO8601:rhsm_timestamp} \[%{LOGLEVEL:rhsm_loglevel}\] %{PROG:rhsm_prog} \@%{DATA:rhsm_module}:%{POSINT:rhsm_module_line} - Response: %{GREEDYDATA:rhsm_response_msg}",
            "%{TIMESTAMP_ISO8601:rhsm_timestamp} \[%{LOGLEVEL:rhsm_loglevel}\] %{PROG:rhsm_prog} \@%{DATA:rhsm_module}:%{POSINT:rhsm_module_line} - %{GREEDYDATA:rhsm_msg}"
            ]
        }
        add_tag => ["rhsm"]
    }


    # why does it feel like I'm writing a parser in some invented language...
    if [rhsm_response_msg] {
        kv { prefix => "rhsm_response_"
             trimkey => ","
             trim => ","
             source => rhsm_response_msg
             add_tag => [ "rhsm_response" ]
             }

        # so we don't end up with an empty %{rhsm_msg}
        mutate {
            replace => [ "rhsm_msg", "%{rhsm_response_msg}" ]
            }
    }

    mutate {
        rename => [ "rhsm_response_requestUuid", "request_uuid" ]
        rename => [ "rhsm_response_status", "response_status" ]
        replace => [ "@message", "%{rhsm_msg}"]
        replace => [ "loglevel", "%{rhsm_loglevel}" ]
        add_field => { "program_name" => "%{rhsm_prog}" }
        }

    date {
      # rhsm.log timestamp is almost ISO8601, but sans timezone
      match => [ "rhsm_timestamp", "YYYY-MM-dd HH:mm:ss,SSS" ]
      }
  }
}

# Use elasticsearch http REST api to send events.
# You probably want to change this.
output {
  elasticsearch {
    host => localhost
    protocol => "http"
  }
  stdout { codec => rubydebug }
}
